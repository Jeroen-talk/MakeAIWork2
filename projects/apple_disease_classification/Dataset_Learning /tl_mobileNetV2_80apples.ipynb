{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5975a85-b424-458e-87a1-a861324fa043",
   "metadata": {},
   "source": [
    "<h4>Tranfer Learning</h4>\n",
    "\n",
    "<p> Zie <a href=\"https://www.tensorflow.org/tutorials/images/transfer_learning\">LINK</a> voor transfer learning op Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "1dc9f91f-50bf-4fb1-a505-99d2a5a44a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# load Tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "f44db172-8e83-4d7b-931a-219f9f4915d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, AvgPool2D, Input, Dropout, Flatten, BatchNormalization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "927cefa0-e379-485e-b208-c03385ab55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opzet datum voor het opslaan van een bestand.\n",
    "from datetime import datetime \n",
    "now = datetime.now()\n",
    "\n",
    "# dd/mm/YY\n",
    "time_save = now.strftime(\"%Hh%M\")\n",
    "dt_save = now.strftime(\"%d%m%Y\")\n",
    "# print(\"ddmmyyyy =\", dt_save)\n",
    "# print(\"HMS =\", time_save)\n",
    "\n",
    "# folder path to save model \n",
    "sp_model = r'saved_models/tl_mobileNetV2_2/model/'\n",
    "sc_model = 0\n",
    "# Iterate directory\n",
    "for path in os.listdir(sp_model):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(sp_model, path)):\n",
    "        sc_model += 1\n",
    "# print('File count:', sc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999b1b79-1571-403e-bb32-14cddd084ff0",
   "metadata": {},
   "source": [
    "<h4>Warning blokker</h4>\n",
    "<p>De lagen in een model geven een warning. De code hieronder blokced het tonen hiervan.</p>    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "515e6177-4a2f-4f94-a69b-83666d75e720",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "61876954-e314-40d4-b4c5-9117b1c50c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset \n",
    "\n",
    "test_data_dir = '../data/Test'\n",
    "train_data_dir = '../data/Train'\n",
    "apples_data_dir = '../data/80apples'\n",
    "\n",
    "\n",
    "data_dir = pathlib.Path(train_data_dir)\n",
    "test_dir = pathlib.Path(test_data_dir)\n",
    "apples_dir = pathlib.Path(apples_data_dir)\n",
    "applesFiles = list()\n",
    "edgeFiles = list()\n",
    "testFiles = list()\n",
    "\n",
    "for filename in os.listdir(train_data_dir):\n",
    "    imgAppleDirectory = os.path.join(train_data_dir, filename)\n",
    "    edgeFiles.append(imgAppleDirectory)\n",
    "    # print(edgeFiles)\n",
    "    \n",
    "for filename in os.listdir(test_data_dir):\n",
    "    imgAppleTestDirectory = os.path.join(test_data_dir, filename)\n",
    "    testFiles.append(imgAppleTestDirectory) \n",
    "    # print(testFiles)\n",
    "    \n",
    "for filename in os.listdir(apples_data_dir):\n",
    "    appleDirectory = os.path.join(apples_data_dir)\n",
    "    applesFiles.append(appleDirectory) \n",
    "    # print(applesFiles)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "ec8d9d03-b3e8-48a8-b324-6025e7265564",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "img_size= (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d80da775-4f12-4b5d-a71b-ce3813d14eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 383 files belonging to 4 classes.\n",
      "Using 307 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=img_size,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "b0180994-4829-4062-a37d-9ff118d755e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 383 files belonging to 4 classes.\n",
      "Using 76 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=img_size,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "8fada6ad-4a17-4efd-8a6c-3f77ff75fbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test set \n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  test_dir,\n",
    "  seed=123,\n",
    "  shuffle=False,\n",
    "  image_size=img_size,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "02f5dd34-1499-4f3a-9bfe-07c23e663d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "apples_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  apples_dir,\n",
    "  seed=123,\n",
    "  shuffle=False,\n",
    "  image_size=img_size,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "18c2366e-c73d-4199-bd11-a7909a011965",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.take(1):\n",
    "#   for i in range(16):\n",
    "#     ax = plt.subplot(4, 4, i + 1)\n",
    "#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#     plt.title(class_names[labels[i]])\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "b1a16d06-7e49-42ee-aeba-b268d2480b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confic dataset for performence \n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "109061f3-f3ca-47f5-af51-26dd433ca20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add augmentation\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.RandomFlip(\"horizontal_and_vertical\", input_shape=(img_height, img_width,3)),\n",
    "  layers.RandomRotation(45.5),\n",
    "  layers.RandomZoom(0.6),  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "dee27842-4dda-41da-9ddc-7777e8d2fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation toegevoegen\n",
    "image, label = next(iter(train_ds))\n",
    "image = tf.cast(tf.expand_dims(image, 0), tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91c1c50-0d6d-40b1-b946-e9190cd600a8",
   "metadata": {},
   "source": [
    "<h4>Base Mobel</h4>\n",
    "<p>Hier wordt het voorgetrainde model ingeladen</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b05c8cc9-1c31-403f-a613-98ce121dd46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "rescale = tf.keras.layers.Rescaling(1./127.5, offset=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "389c3625-78b8-49d8-bfdb-768d664e166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (224, 224, 3)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "b236494e-e289-4bd9-914f-9680d4b9a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch =  next(iter(train_ds))\n",
    "feature_batch = base_model(image_batch)\n",
    "# print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "38e071cf-d775-476f-9e18-e16f337b796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Freeze the convolutional base\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87dc724-6df2-4520-ad54-ef1b1cf012db",
   "metadata": {},
   "source": [
    "<h4>Classification head</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "72d43375-e42c-4ec1-b300-1ff95bbc677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "# print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "eb2e12d7-122c-4ad6-ae34-810144972942",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_layer = tf.keras.layers.Dense(4, activation = 'softmax')\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "# print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "15244428-8d31-4709-8700-eae700c0d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base model architecture\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "de766bba-ba22-4026-a219-27e20e843d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "outputs = prediction_layer(x)\n",
    "preds=Dense(num_classes, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs, outputs=preds)\n",
    "# keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "6b283541-f168-48e3-86b1-ca9d90c50118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_13\n",
      "1 sequential_4\n",
      "2 tf.math.truediv_7\n",
      "3 tf.math.subtract_7\n",
      "4 mobilenetv2_1.00_224\n",
      "5 global_average_pooling2d_4\n",
      "6 dropout_7\n",
      "7 flatten_7\n",
      "8 dense_12\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "    print(i,layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4468b72b-6d64-40dc-b160-dd3f1c5c189c",
   "metadata": {},
   "source": [
    "<h4>Model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "01ce291b-1e27-4cf8-bfd8-3aa74ecdf111",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "888ff9b5-a183-466a-9dd9-bc0594ccf149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "5887d6aa-83ab-4b1c-9f7d-e02e19e98024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0f457b-eedd-4127-be23-b3a2e5b4ec18",
   "metadata": {},
   "source": [
    "<h4>Model Training</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "0a2084d9-54b9-4aef-a980-e565ab4e2e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 299ms/step - loss: 1.5776 - accuracy: 0.2632\n"
     ]
    }
   ],
   "source": [
    "initial_epochs = 25\n",
    "loss0, accuracy0 = model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "af97b6c2-6e4f-4e2b-9277-bbe96798e89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss: 1.58\n",
      "initial accuracy: 0.26\n"
     ]
    }
   ],
   "source": [
    "print(\"initial loss: {:.2f}\".format(loss0))\n",
    "print(\"initial accuracy: {:.2f}\".format(accuracy0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "872fcbed-f51a-46e5-9f16-5bdb99dd68ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add Tensorboard\n",
    "log_dir = \"logs/fit\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "9e909665-2a00-4750-a54d-aaa047abb8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "20/20 [==============================] - 19s 652ms/step - loss: 1.7778 - accuracy: 0.3094 - val_loss: 1.4749 - val_accuracy: 0.3289\n",
      "Epoch 2/25\n",
      "20/20 [==============================] - 12s 600ms/step - loss: 1.7743 - accuracy: 0.2964 - val_loss: 1.4005 - val_accuracy: 0.3947\n",
      "Epoch 3/25\n",
      "20/20 [==============================] - 12s 581ms/step - loss: 1.7152 - accuracy: 0.3029 - val_loss: 1.3392 - val_accuracy: 0.4079\n",
      "Epoch 4/25\n",
      "20/20 [==============================] - 12s 584ms/step - loss: 1.6201 - accuracy: 0.3583 - val_loss: 1.2877 - val_accuracy: 0.4474\n",
      "Epoch 5/25\n",
      "20/20 [==============================] - 12s 585ms/step - loss: 1.4928 - accuracy: 0.3616 - val_loss: 1.2406 - val_accuracy: 0.4737\n",
      "Epoch 6/25\n",
      "20/20 [==============================] - 12s 604ms/step - loss: 1.4646 - accuracy: 0.3909 - val_loss: 1.1911 - val_accuracy: 0.5000\n",
      "Epoch 7/25\n",
      "20/20 [==============================] - 12s 577ms/step - loss: 1.3506 - accuracy: 0.4202 - val_loss: 1.1501 - val_accuracy: 0.5132\n",
      "Epoch 8/25\n",
      "20/20 [==============================] - 11s 564ms/step - loss: 1.3366 - accuracy: 0.4658 - val_loss: 1.1095 - val_accuracy: 0.5263\n",
      "Epoch 9/25\n",
      "20/20 [==============================] - 11s 543ms/step - loss: 1.3380 - accuracy: 0.4625 - val_loss: 1.0690 - val_accuracy: 0.5526\n",
      "Epoch 10/25\n",
      "20/20 [==============================] - 12s 588ms/step - loss: 1.2635 - accuracy: 0.4886 - val_loss: 1.0333 - val_accuracy: 0.6184\n",
      "Epoch 11/25\n",
      "20/20 [==============================] - 15s 744ms/step - loss: 1.3029 - accuracy: 0.4919 - val_loss: 1.0056 - val_accuracy: 0.6316\n",
      "Epoch 12/25\n",
      "20/20 [==============================] - 14s 707ms/step - loss: 1.2412 - accuracy: 0.4625 - val_loss: 0.9793 - val_accuracy: 0.6316\n",
      "Epoch 13/25\n",
      "20/20 [==============================] - 13s 645ms/step - loss: 1.1692 - accuracy: 0.5244 - val_loss: 0.9587 - val_accuracy: 0.6316\n",
      "Epoch 14/25\n",
      "20/20 [==============================] - 13s 645ms/step - loss: 1.1059 - accuracy: 0.5570 - val_loss: 0.9381 - val_accuracy: 0.6447\n",
      "Epoch 15/25\n",
      "20/20 [==============================] - 12s 586ms/step - loss: 1.0554 - accuracy: 0.5505 - val_loss: 0.9210 - val_accuracy: 0.6447\n",
      "Epoch 16/25\n",
      "20/20 [==============================] - 14s 717ms/step - loss: 1.1229 - accuracy: 0.5440 - val_loss: 0.8902 - val_accuracy: 0.6579\n",
      "Epoch 17/25\n",
      "20/20 [==============================] - 13s 627ms/step - loss: 1.0480 - accuracy: 0.5472 - val_loss: 0.8660 - val_accuracy: 0.6711\n",
      "Epoch 18/25\n",
      "20/20 [==============================] - 12s 575ms/step - loss: 1.1092 - accuracy: 0.5244 - val_loss: 0.8510 - val_accuracy: 0.6842\n",
      "Epoch 19/25\n",
      "20/20 [==============================] - 12s 579ms/step - loss: 1.0175 - accuracy: 0.5798 - val_loss: 0.8313 - val_accuracy: 0.6974\n",
      "Epoch 20/25\n",
      "20/20 [==============================] - 12s 584ms/step - loss: 1.0520 - accuracy: 0.5863 - val_loss: 0.8151 - val_accuracy: 0.7237\n",
      "Epoch 21/25\n",
      "20/20 [==============================] - 12s 599ms/step - loss: 0.9227 - accuracy: 0.6026 - val_loss: 0.7941 - val_accuracy: 0.7237\n",
      "Epoch 22/25\n",
      "20/20 [==============================] - 12s 576ms/step - loss: 0.9476 - accuracy: 0.6124 - val_loss: 0.7762 - val_accuracy: 0.7237\n",
      "Epoch 23/25\n",
      "20/20 [==============================] - 11s 562ms/step - loss: 0.9011 - accuracy: 0.6189 - val_loss: 0.7749 - val_accuracy: 0.7368\n",
      "Epoch 24/25\n",
      "20/20 [==============================] - 12s 593ms/step - loss: 0.8066 - accuracy: 0.6710 - val_loss: 0.7601 - val_accuracy: 0.7500\n",
      "Epoch 25/25\n",
      "20/20 [==============================] - 13s 663ms/step - loss: 0.9207 - accuracy: 0.6482 - val_loss: 0.7405 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=val_ds,\n",
    "                    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b54fa9ab-c776-4136-9ad0-376fce8dcef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# plt.figure(figsize=(18, 18))\n",
    "# plt.subplot(2, 1, 1)\n",
    "# plt.plot(acc, label='Training Accuracy')\n",
    "# plt.plot(val_acc, label='Validation Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.ylim([min(plt.ylim()),1])\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# plt.subplot(2, 1, 2)\n",
    "# plt.plot(loss, label='Training Loss')\n",
    "# plt.plot(val_loss, label='Validation Loss')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.ylabel('Cross Entropy')\n",
    "# plt.ylim([0,5.0])\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.xlabel('epoch')\n",
    "# # plt.savefig('saved_models/tl_mobileNetV2_2/plt_val_acc/tl_freese_' + str(dt_save) + '_' + str(time_save) + '_' + str(sc_model) + '.png')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7c612-428c-4fb6-85f3-51dd000505dd",
   "metadata": {},
   "source": [
    "<h4>UN-FREESE</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "45f18c5c-352c-4d59-aecd-cdc81a51b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "069d35e3-cebf-49f6-a9e0-b64c3e95a4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aantal layers in het basis model:  154\n"
     ]
    }
   ],
   "source": [
    "print(\"Aantal layers in het basis model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "e5ad13e7-d2fc-4749-a381-e1e69617f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze alle layers voor 'fine_tune_at' layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec62ab9-1c07-42cf-9b8e-48e334a652ab",
   "metadata": {},
   "source": [
    "<h4>Het model terug samenstellen</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "ef536ec4-3da9-4366-83a7-9f0b04cb73fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate/10),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "ae6079a2-6f5f-4511-a97e-accb9323c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "0a98bfc4-e0ed-4829-bc00-109b01aff397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3799d09-fa11-44d4-9c2f-db1599b27c50",
   "metadata": {},
   "source": [
    "<h4>Voortzetting Model training, na de Un-Freese</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "5603dc19-f3f6-4145-a1cc-d6a360a9d50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "20/20 [==============================] - 26s 800ms/step - loss: 0.8091 - accuracy: 0.6678 - val_loss: 0.6516 - val_accuracy: 0.8026\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 16s 779ms/step - loss: 0.7183 - accuracy: 0.7492 - val_loss: 0.5651 - val_accuracy: 0.8158\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 15s 774ms/step - loss: 0.6776 - accuracy: 0.7427 - val_loss: 0.5408 - val_accuracy: 0.8026\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 15s 736ms/step - loss: 0.5720 - accuracy: 0.7948 - val_loss: 0.4568 - val_accuracy: 0.8421\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 16s 791ms/step - loss: 0.5827 - accuracy: 0.7622 - val_loss: 0.4699 - val_accuracy: 0.8158\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 16s 799ms/step - loss: 0.5256 - accuracy: 0.8078 - val_loss: 0.4018 - val_accuracy: 0.8421\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 17s 846ms/step - loss: 0.4846 - accuracy: 0.8111 - val_loss: 0.3417 - val_accuracy: 0.8553\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 16s 780ms/step - loss: 0.4963 - accuracy: 0.8143 - val_loss: 0.3980 - val_accuracy: 0.8421\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 16s 804ms/step - loss: 0.4829 - accuracy: 0.8208 - val_loss: 0.3551 - val_accuracy: 0.8684\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 16s 820ms/step - loss: 0.4317 - accuracy: 0.8176 - val_loss: 0.3428 - val_accuracy: 0.8684\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 15s 733ms/step - loss: 0.4423 - accuracy: 0.8502 - val_loss: 0.3874 - val_accuracy: 0.8684\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 17s 852ms/step - loss: 0.3545 - accuracy: 0.8567 - val_loss: 0.3321 - val_accuracy: 0.8684\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 17s 826ms/step - loss: 0.3898 - accuracy: 0.8730 - val_loss: 0.3694 - val_accuracy: 0.8684\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 15s 766ms/step - loss: 0.3982 - accuracy: 0.8697 - val_loss: 0.2722 - val_accuracy: 0.8947\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 18s 900ms/step - loss: 0.4328 - accuracy: 0.8534 - val_loss: 0.3765 - val_accuracy: 0.8684\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 16s 809ms/step - loss: 0.3275 - accuracy: 0.8860 - val_loss: 0.3345 - val_accuracy: 0.8684\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 17s 858ms/step - loss: 0.3348 - accuracy: 0.8860 - val_loss: 0.3259 - val_accuracy: 0.8684\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 15s 731ms/step - loss: 0.3224 - accuracy: 0.8795 - val_loss: 0.2878 - val_accuracy: 0.8684\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 13s 636ms/step - loss: 0.3090 - accuracy: 0.8827 - val_loss: 0.3632 - val_accuracy: 0.8684\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 12s 615ms/step - loss: 0.2899 - accuracy: 0.8925 - val_loss: 0.3284 - val_accuracy: 0.8684\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 16s 795ms/step - loss: 0.2890 - accuracy: 0.8860 - val_loss: 0.3316 - val_accuracy: 0.8684\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 14s 700ms/step - loss: 0.2787 - accuracy: 0.8990 - val_loss: 0.2716 - val_accuracy: 0.8947\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 16s 788ms/step - loss: 0.2901 - accuracy: 0.8860 - val_loss: 0.3067 - val_accuracy: 0.8684\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 16s 771ms/step - loss: 0.2661 - accuracy: 0.9186 - val_loss: 0.2794 - val_accuracy: 0.8947\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 14s 674ms/step - loss: 0.3212 - accuracy: 0.8860 - val_loss: 0.2969 - val_accuracy: 0.8684\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 13s 637ms/step - loss: 0.2899 - accuracy: 0.9153 - val_loss: 0.3389 - val_accuracy: 0.8684\n"
     ]
    }
   ],
   "source": [
    "fine_tune_epochs = 25\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                    epochs=total_epochs,\n",
    "                    initial_epoch=history.epoch[-1],\n",
    "                    validation_data=val_ds,\n",
    "                    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "1b0c51e5-8a04-4b3f-822b-7d7337bd723b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'float' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [326], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m history_fine\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m val_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m history_fine\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m history_fine\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m history_fine\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'float' and 'list'"
     ]
    }
   ],
   "source": [
    "acc += history_fine.history['accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eec4f6-8cb5-4fc5-9c78-f44b05f0afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(18, 18))\n",
    "# plt.subplot(2, 1, 1)\n",
    "# plt.plot(acc, label='Training Accuracy')\n",
    "# plt.plot(val_acc, label='Validation Accuracy')\n",
    "# plt.ylim([min(plt.ylim()),1])\n",
    "# plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "#           plt.ylim(), label='Start Fine Tuning')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "\n",
    "\n",
    "# plt.subplot(2, 1, 2)\n",
    "# plt.plot(loss, label='Training Loss')\n",
    "# plt.plot(val_loss, label='Validation Loss')\n",
    "# plt.ylim([0, 5.0])\n",
    "# plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "#          plt.ylim(), label='Start Fine Tuning')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.xlabel('epoch')\n",
    "\n",
    "\n",
    "# plt.subplot(2, 1, 2)\n",
    "# plt.plot(loss, label='Training Loss')\n",
    "# plt.plot(val_loss, label='Validation Loss')\n",
    "# plt.ylim([0,5.0])\n",
    "# plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "#          plt.ylim(), label='Start Fine Tuning')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.savefig('saved_models/tl_mobileNetV2_2/plt_val_acc/tl_UNfreese_' + str(dt_save) + '_' + str(time_save) + '_' + str(sc_model) + '.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61c8c42-e149-41fa-a986-259e8ed20fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('saved_models/tl_mobileNetV2/model/tl_' + str(dt_save) + '_' + str(time_save) + '_' + str(sc_model) + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07cc7a2-ae42-436c-96c9-e29317b31120",
   "metadata": {},
   "source": [
    "<h4>Confusion Matrix</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "979b196a-a153-4e8d-bbf7-e093cf6cf7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 3s 260ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "batchPredictions = model.predict(test_ds)\n",
    "predicted_categories = tf.argmax(batchPredictions, axis=1)\n",
    "true_categories = tf.concat([y for x, y in test_ds], axis=0)\n",
    "\n",
    "confusion_matrix(predicted_categories, true_categories)\n",
    "\n",
    "confusion_matrix = confusion_matrix(true_categories, predicted_categories)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_matrix,display_labels = ['Blotch', 'Normal', 'Rot', 'Scab'])\n",
    "\n",
    "cm_display.plot()\n",
    "# plt.savefig('saved_models/tl_mobileNetV2_2/plt_matrix/tl_matrix_' + str(dt_save) + '_' + str(time_save) + '_' + str(sc_model) + '.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f7a052-6218-4d1c-9869-ed2dda630a9e",
   "metadata": {},
   "source": [
    "###### <h4>Evaluatie en voorspelling</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "65a6430a-6d32-4ffe-a656-517ab58bca5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 264ms/step - loss: 0.6193 - accuracy: 0.7917\n",
      "Test accuracy : 0.7916666865348816\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "7f255db8-4f42-4501-8c40-c819e4cef4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Labels:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "image_batch, label_batch = test_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(16):\n",
    "#     ax = plt.subplot(4, 4, i + 1)\n",
    "#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#     plt.title(class_names[labels[i]])\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "a0c52c47-33a7-4692-aec5-47f6d5977296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      " [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Labels:\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "image_batch, label_batch = apples_ds.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for i in range(16):\n",
    "#     ax = plt.subplot(4, 4, i + 1)\n",
    "#     plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#     plt.title(class_names[labels[i]])\n",
    "#     plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "857eb37b-7e83-496d-a247-3827c377815c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 6 8]\n",
      "[2 4 6 8]\n"
     ]
    }
   ],
   "source": [
    "vector = np.vectorize(np.int_)\n",
    "y = np.array([2, 4, 6, 8])\n",
    "x = vector(y)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "# [2, 4, 6, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "451ab3b4-5165-4057-8bac-02d071915499",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'numpy.vectorize'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [325], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m img_array \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Create batch axis\u001b[39;00m\n\u001b[1;32m      6\u001b[0m vectorApple \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvectorize(np\u001b[38;5;241m.\u001b[39mint_)\n\u001b[0;32m----> 7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvectorApple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m applePredict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(predictions[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(applePredict)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/keras/engine/data_adapter.py:1083\u001b[0m, in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1080\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m ALL_ADAPTER_CLS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mcan_handle(x, y)]\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m adapter_cls:\n\u001b[1;32m   1082\u001b[0m     \u001b[38;5;66;03m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[39;00m\n\u001b[0;32m-> 1083\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1084\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to find data adapter that can handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1085\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(_type_name(x), _type_name(y))\n\u001b[1;32m   1086\u001b[0m     )\n\u001b[1;32m   1087\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapter_cls) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1089\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData adapters should be mutually exclusive for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1090\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandling inputs. Found multiple adapters \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m to handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1091\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(adapter_cls, _type_name(x), _type_name(y))\n\u001b[1;32m   1092\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.vectorize'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "img = keras.preprocessing.image.load_img(\n",
    "    \"../data/80apples/naamloze map/1832065205.jpg\", target_size=img_size\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 1)  # Create batch axis\n",
    "vectorApple = np.vectorize(np.int_)\n",
    "predictions = model.predict(vectorApple)\n",
    "\n",
    "applePredict = float(predictions[0])\n",
    "print(applePredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe4468e-b963-4c97-a9d9-b04ebd387a9b",
   "metadata": {},
   "source": [
    "<h2><a herf='https://keras.io/examples/vision/image_classification_from_scratch/' target='_blank' >Zie <strong>link</strong></a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7aa5a4-fc01-4fe6-b702-cfebd0ddf1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run Tensorbord\n",
    "%tensorboard --logdir logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63ff341-d820-43b2-90be-afafd2d5aceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
