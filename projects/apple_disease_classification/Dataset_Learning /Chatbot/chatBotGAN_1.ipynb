{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec702f7-1c9f-4cfe-a0be-020204175059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a8fd7edf-0eeb-4aa8-be95-064aefae9b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e5cadee9-2b8f-401a-b754-2bb0a2b00ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sentences for encoding of the apple batch\n",
    "sentences = [\n",
    "            'The Batch of apples has class 3.',\n",
    "            'Apple class is 3.',\n",
    "            'Classification of the batch of apples is 3.'\n",
    "            '3 is the classificationnumber.',\n",
    "            'Batchclass is 3.',\n",
    "            'The batch has 4 blotched apples.',\n",
    "            '4 blotched appels are in this batch.',\n",
    "            'You have 3 scabbed apples in this batch.',\n",
    "            'The bast has 3 apples classified as beeing scab.',\n",
    "            'There are 72 healthy apples.', \n",
    "            'This batch conssits 72 healthy apples.',\n",
    "            '1 apple was rot.',\n",
    "            'Only 1 apple was classified as beeing rot.',\n",
    "            'The batch conssits between the 5.000 and 10.000 apples.',\n",
    "            'Batch size is between 5.000 and 10.000.',\n",
    "            '80 apples are beeing checked',\n",
    "            'From this batch 80 apples where checked'\n",
    "            ]\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Print the embeddings\n",
    "for sentence, embedding in zip(sentences, embeddings):\n",
    "    # print(\"Sentence:\", sentence)\n",
    "    # print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92448ae3-bf5d-42b3-89a3-9a624cbb5d39",
   "metadata": {},
   "source": [
    "<h2>Comparing Sentence Similarities</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b178c10e-9213-4a6e-8189-beccaf60607a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine-Similarity: tensor([[0.8866]])\n"
     ]
    }
   ],
   "source": [
    "#Sentences are encoded by calling model.encode()\n",
    "emb1 = model.encode(\"Whats the class of the Apple batch?\")\n",
    "emb2 = model.encode(\"Can you tell me the class of this batch?\")\n",
    "emb3 = model.encode(\"I would like to know the classification of this batch?\")\n",
    "cos_sim = util.cos_sim(emb2, emb3)\n",
    "print(\"Cosine-Similarity:\", cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4af7fef0-69b6-4948-87ca-f0e8e1b1956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentence_combinations = []\n",
    "for i in range(len(cos_sim)-1):\n",
    "    for j in range(i+1, len(cos_sim)):\n",
    "        all_sentence_combinations.append([cos_sim[i][j], i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e0107531-ab02-432f-ab15-04f2da7081d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 most similar pairs:\n",
      "1 apple was rot. \t Only 1 apple was classified as beeing rot. \t 0.8493\n",
      "There are 72 healthy apples. \t This batch conssits 72 healthy apples. \t 0.8482\n",
      "The Batch of apples has class 3. \t Classification of the batch of apples is 3.3 is the classificationnumber. \t 0.7915\n",
      "The batch has 4 blotched apples. \t The batch conssits between the 5.000 and 10.000 apples. \t 0.7888\n",
      "The batch has 4 blotched apples. \t This batch conssits 72 healthy apples. \t 0.7827\n"
     ]
    }
   ],
   "source": [
    "# sentences \n",
    "\n",
    "corpus = [\n",
    "            'The Batch of apples has class 3.',\n",
    "            'Apple class is 3.',\n",
    "            'Classification of the batch of apples is 3.',\n",
    "            '3 is the classificationnumber.',\n",
    "            'Batchclass is 3.',\n",
    "            'The batch has 4 blotched apples.',\n",
    "            '4 blotched appels are in this batch.',\n",
    "            'You have 3 scabbed apples in this batch.',\n",
    "            'The bast has 3 apples classified as beeing scab.',\n",
    "            'There are 72 healthy apples.', \n",
    "            'This batch conssits 72 healthy apples.',\n",
    "            '1 apple was rot.',\n",
    "            'Only 1 apple was classified as beeing rot.',\n",
    "            'The batch conssits between the 5.000 and 10.000 apples.',\n",
    "            'Batch size is between 5.000 and 10.000.',\n",
    "            '80 apples are beeing checked',\n",
    "            'From this batch 80 apples where checked'\n",
    "          ]\n",
    "\n",
    "#Encode all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Add all pairs to a list with their cosine similarity score\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(cos_sim)-1):\n",
    "    for j in range(i+1, len(cos_sim)):\n",
    "        all_sentence_combinations.append([cos_sim[i][j], i, j])\n",
    "\n",
    "#Sort list by the highest cosine similarity score\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(\"Top-5 most similar pairs:\")\n",
    "for score, i, j in all_sentence_combinations[0:5]:\n",
    "    print(\"{} \\t {} \\t {:.4f}\".format(sentences[i], sentences[j], cos_sim[i][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1582e35-d29c-49b0-a8e9-64f18bf423be",
   "metadata": {},
   "source": [
    "<h2>Semantic Search</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2d05511e-eab5-4bc5-9b9c-c97bed7b05bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: The apple batch classification\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "Classification of the batch of apples is 3. (Score: 0.6819) \n",
      "\n",
      "The Batch of apples has class 3. (Score: 0.6466) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Corpus with example sentences\n",
    "# corpus = ['What is the classification of the batch']\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['The apple batch classification']\n",
    "\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = min(2, len(corpus))\n",
    "for query in queries:\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    # We use cosine-similarity and torch.topk to find the highest 5 scores\n",
    "    cos_scores = util.cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        print(corpus[idx], \"(Score: {:.4f})\".format(score),'\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1f744594-55bb-40e5-ab40-47e9b651a731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification of the batch of apples is 3.3 is the classificationnumber. (Score: 0.6661)\n",
      "The Batch of apples has class 3. (Score: 0.6466)\n",
      "The batch conssits between the 5.000 and 10.000 apples. (Score: 0.5876)\n",
      "From this batch 80 apples where checked (Score: 0.5692)\n",
      "The batch has 4 blotched apples. (Score: 0.5602)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    \"\"\"\n",
    "    # Alternatively, we can also use util.semantic_search to perform cosine similarty + topk\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "    hits = hits[0]      #Get the hits for the first query\n",
    "    for hit in hits:\n",
    "        print(corpus[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))\n",
    "    \"\"\"\n",
    "    \n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=5)\n",
    "    hits = hits[0]      #Get the hits for the first query\n",
    "    for hit in hits:\n",
    "        print(corpus[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f11828-62d7-4856-ab10-1d76f1be97c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
